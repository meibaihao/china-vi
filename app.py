import streamlit as st
import pandas as pd
import numpy as np
import joblib
import os
import time
import glob

# --- 1. é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="ä¸­è€å¹´äººè§†åŠ›éšœç¢é£é™©é¢„æµ‹ç³»ç»Ÿ",
    page_icon="ğŸ‘“",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰å¤–è§‚
st.markdown("""
    <style>
    .main { background-color: #f8f9fa; }
    .stButton>button {
        width: 100%;
        border-radius: 8px;
        height: 3.5em;
        background-color: #007bff;
        color: white;
        font-weight: bold;
    }
    </style>
    """, unsafe_allow_html=True)

# --- 2. èµ„æºåŠ è½½ ---
@st.cache_resource
def load_assets():
    try:
        model_files = glob.glob('model_assets/best_model*.pkl')
        if not model_files:
            return None, None, None, "æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶"
        
        model = joblib.load(model_files[0])
        scaler = joblib.load('model_assets/scaler.pkl')
        encoders = joblib.load('model_assets/label_encoders.pkl')
        
        # ä¸¥æ ¼æŒ‰ç…§æ‚¨æä¾›çš„ 70 ä¸ªç‰¹å¾é¡ºåºè¿›è¡ŒåŠ è½½
        with open('model_assets/feature_list.txt', 'r', encoding='utf-8') as f:
            features = [line.strip().split('. ')[1] for line in f.readlines() if '. ' in line]
        return model, scaler, encoders, features
    except Exception as e:
        return None, None, None, str(e)

model, scaler, encoders, feature_list = load_assets()

# --- 3. æ ¸å¿ƒå˜é‡å®šä¹‰ (åŸºäº SHAP å›¾æ’åº) ---
# æ˜ å°„è¯´æ˜ï¼š
# å¬åŠ›éšœç¢ -> hear, å‡ºç”Ÿåœ°åŒº -> rural, å¹´é¾„ -> age, æ•™è‚²æƒ…å†µ -> edu, è®¤çŸ¥èƒ½åŠ› -> total_cognition
# å±…ä½ç¯å¢ƒ -> water, å­å¥³æ”¯æŒ -> hchild, å¿ƒæ™ºçŠ¶å†µ -> psyche, è®°å¿†èƒ½åŠ› -> memrye, é€€ä¼‘çŠ¶å†µ -> pension
# ä½“é‡ -> mweight, ç¤¾ä¼šè¯„åˆ† -> social_total, ç–¼ç—›è¯„åˆ† -> da042s_total, æ”¶å…¥ -> income_total, èº«é«˜ -> mheight
TOP_15_SHAP_FEATURES = [
    'hear', 'rural', 'age', 'edu', 'total_cognition', 
    'water', 'hchild', 'psyche', 'memrye', 'pension', 
    'mweight', 'social_total', 'da042s_total', 'income_total', 'mheight'
]

# é€‰é¡¹æ˜ å°„
MAPS = {
    'gender': {"1": "ç”·", "2": "å¥³"},
    'rural': {"1": "åŸé•‡", "2": "å†œæ‘"},
    'edu': {"1": "é«˜ä¸­åŠä»¥ä¸Š", "2": "ä¸­å­¦", "3": "å°å­¦", "4": "ä¸è¯†å­—/åŠä¸è¯†å­—"},
    'hear': {"0": "æ­£å¸¸", "1": "æœ‰éšœç¢"},
    'pension': {"0": "æ— ", "1": "æœ‰"},
    'psyche': {"0": "è‰¯å¥½", "1": "æœ‰å¿ƒç†/ç²¾ç¥å‹åŠ›"},
    'memrye': {"1": "ä¼˜", "2": "è‰¯", "3": "ä¸€èˆ¬", "4": "å·®", "5": "æå·®"},
    'water': {"1": "è‡ªæ¥æ°´", "2": "äº•æ°´/æ³‰æ°´", "3": "å…¶ä»–"},
    'binary': {"0": "å¦", "1": "æ˜¯"}
}

# --- 4. ç•Œé¢å±•ç¤º ---
st.title("ğŸ‘“ ä¸­è€å¹´äººè§†åŠ›éšœç¢é£é™©ç­›æŸ¥ç³»ç»Ÿ")
st.markdown("---")

if model is None:
    st.error(f"âŒ èµ„æºåŠ è½½å¤±è´¥: {feature_list}")
    st.stop()

# æ¨¡å¼é€‰æ‹©
st.subheader("ç¬¬ä¸€æ­¥ï¼šé€‰æ‹©é¢„æµ‹æ¨¡å¼")
mode = st.selectbox(
    "æ ¹æ® SHAP é‡è¦æ€§è¯„ä¼°ï¼Œå»ºè®®ä½¿ç”¨ç²¾ç®€ç‰ˆè¿›è¡Œå¿«é€Ÿç­›æŸ¥ï¼š",
    options=["è¯·é€‰æ‹©æ¨¡å¼...", "ç²¾ç®€ç‰ˆ (åŸºäºæ ¸å¿ƒ 15 é¡¹æŒ‡æ ‡)", "å®Œæ•´ç‰ˆ (å…¨é‡ 70 é¡¹æŒ‡æ ‡)"]
)

if mode == "è¯·é€‰æ‹©æ¨¡å¼...":
    st.stop()

st.markdown("---")
st.subheader("ç¬¬äºŒæ­¥ï¼šå½•å…¥å—è¯•è€…ä¿¡æ¯")

user_inputs = {}
is_simplified = "ç²¾ç®€ç‰ˆ" in mode

# å¸ƒå±€è®¾è®¡
tab1, tab2, tab3 = st.tabs(["ğŸ§¬ äººå£å­¦ä¸èº«ä½“æŒ‡æ ‡", "ğŸ§  è®¤çŸ¥ä¸å¿ƒç†", "ğŸ¡ ç”Ÿæ´»ç¯å¢ƒä¸ç¤¾ä¼š"])

with tab1:
    c1, c2 = st.columns(2)
    with c1:
        user_inputs['age'] = st.number_input("å¹´é¾„ (age)", 45, 120, 65)
        user_inputs['mheight'] = st.number_input("èº«é«˜ cm (mheight)", 100, 220, 160)
        user_inputs['mweight'] = st.number_input("ä½“é‡ kg (mweight)", 30, 150, 60)
    with c2:
        user_inputs['rural'] = st.selectbox("å±…ä½/å‡ºç”Ÿåœ°åŒº (rural)", ["1", "2"], format_func=lambda x: MAPS['rural'][x])
        user_inputs['edu'] = st.selectbox("å—æ•™è‚²æƒ…å†µ (edu)", ["1", "2", "3", "4"], format_func=lambda x: MAPS['edu'][x])
        user_inputs['income_total'] = st.number_input("å¹´æ€»æ”¶å…¥ (income_total)", 0, 1000000, 20000)

with tab2:
    c3, c4 = st.columns(2)
    with c3:
        user_inputs['hear'] = st.selectbox("å¬åŠ›éšœç¢æƒ…å†µ (hear)", ["0", "1"], format_func=lambda x: MAPS['hear'][x])
        user_inputs['total_cognition'] = st.slider("è®¤çŸ¥èƒ½åŠ›è¯„åˆ† (total_cognition)", 0, 40, 20)
        user_inputs['memrye'] = st.selectbox("è®°å¿†èƒ½åŠ›è¯„ä»· (memrye)", ["1", "2", "3", "4", "5"], format_func=lambda x: MAPS['memrye'][x])
    with c4:
        user_inputs['psyche'] = st.selectbox("å¿ƒæ™º/ç²¾ç¥çŠ¶å†µ (psyche)", ["0", "1"], format_func=lambda x: MAPS['psyche'][x])
        user_inputs['da042s_total'] = st.number_input("èº«ä½“ç–¼ç—›è¯„åˆ† (da042s_total)", 0, 50, 5)

with tab3:
    c5, c6 = st.columns(2)
    with c5:
        user_inputs['water'] = st.selectbox("å±…ä½é¥®æ°´ç¯å¢ƒ (water)", ["1", "2", "3"], format_func=lambda x: MAPS['water'][x])
        user_inputs['hchild'] = st.number_input("å­å¥³æ”¯æŒ/æ•°é‡ (hchild)", 0, 15, 2)
    with c6:
        user_inputs['social_total'] = st.number_input("ç¤¾ä¼šæ´»åŠ¨å‚ä¸è¯„åˆ† (social_total)", 0, 100, 30)
        user_inputs['pension'] = st.selectbox("é€€ä¼‘é‡‘çŠ¶å†µ (pension)", ["0", "1"], format_func=lambda x: MAPS['pension'][x])

# å®Œæ•´ç‰ˆè¡¥å……è¾“å…¥
if not is_simplified:
    with st.expander("ğŸ” å½•å…¥å…¶ä½™è¡¥å……ç‰¹å¾ (éæ ¸å¿ƒå˜é‡)"):
        st.info("ä»¥ä¸‹ç‰¹å¾å°†ä½¿ç”¨é»˜è®¤å€¼å¡«å……ï¼Œå¦‚æœ‰æ•°æ®è¯·ä¿®æ”¹ã€‚")
        remaining_features = [f for f in feature_list if f not in user_inputs]
        cols = st.columns(3)
        for idx, feat in enumerate(remaining_features):
            user_inputs[feat] = cols[idx % 3].number_input(f"{feat}", value=0.0)

# --- 5. é¢„æµ‹æ‰§è¡Œ ---
st.markdown("---")
if st.button("ğŸš€ å¼€å§‹ AI é£é™©è¯„ä¼°"):
    with st.status("æ­£åœ¨è°ƒå–é¢„æµ‹å¼•æ“...", expanded=True) as status:
        # 1. ç‰¹å¾å…¨é‡å¯¹é½ (å…³é”®æ­¥ï¼šè¡¥é½ 70 ä¸ªç‰¹å¾)
        full_data = {}
        for feat in feature_list:
            # å¦‚æœæ˜¯ç²¾ç®€ç‰ˆä¸­æœªå½•å…¥çš„å˜é‡ï¼Œå¡«å…… 0
            full_data[feat] = user_inputs.get(feat, 0)
        
        # è½¬æ¢ä¸º DataFrame å¹¶ä¸¥æ ¼æ’åº
        df = pd.DataFrame([full_data])[feature_list]
        
        # 2. æ ‡ç­¾ç¼–ç 
        for col, le in encoders.items():
            if col in df.columns:
                val = str(df[col].values[0])
                df[col] = le.transform([val])[0] if val in le.classes_ else 0
        
        # 3. é¢„æµ‹
        df_scaled = scaler.transform(df)
        prob = model.predict_proba(df_scaled)[:, 1][0]
        is_high_risk = prob >= OPTIMAL_THRESHOLD
        
        status.update(label="è®¡ç®—å®Œæˆï¼", state="complete", expanded=False)

    # --- 6. ç»“æœå±•ç¤º ---
    st.subheader("ğŸ“Š è¯„ä¼°ç»“æœæŠ¥å‘Š")
    col_res1, col_res2 = st.columns([1, 2])
    
    with col_res1:
        st.metric(label="è§†åŠ›éšœç¢æ‚£ç—…æ¦‚ç‡", value=f"{prob:.2%}")
        if is_high_risk:
            st.error("ç»“è®ºï¼šé«˜é£é™©äººç¾¤")
        else:
            st.success("ç»“è®ºï¼šä½é£é™©äººç¾¤")
            st.balloons()

    with col_res2:
        st.write("#### é£é™©èµ°åŠ¿")
        st.progress(prob)
        st.caption(f"å½“å‰åˆ¤æ–­é˜ˆå€¼ä¸º: {OPTIMAL_THRESHOLD}")
        if is_high_risk:
            st.warning("âš ï¸ å»ºè®®ï¼šæ£€æµ‹åˆ°è¾ƒé«˜é£é™©ã€‚å»ºè®®å—è¯•è€…å°½å¿«å‰å¾€åŒ»é™¢çœ¼ç§‘è¿›è¡Œä¸“ä¸šéªŒå…‰å’Œçœ¼åº•æ£€æŸ¥ã€‚")
        else:
            st.info("ğŸ’¡ å»ºè®®ï¼šç›®å‰é£é™©è¾ƒä½ï¼Œå»ºè®®ä¿æŒè‰¯å¥½çš„ç”¨çœ¼ä¹ æƒ¯ï¼Œå¹¶å®šæœŸè¿›è¡Œå¹´åº¦çœ¼ç§‘æ£€æŸ¥ã€‚")

# --- 7. ç³»ç»ŸåŸç† ---
with st.expander("ğŸ”¬ é¢„æµ‹åŸç†è¯´æ˜"):
    st.write("æœ¬ç³»ç»ŸåŸºäº **Gradient Boosting (æ¢¯åº¦æå‡æ ‘)** ç®—æ³•å¼€å‘ï¼Œå¹¶ä½¿ç”¨ **SHAP** è§£é‡Šå·¥å…·ç¡®å®šç‰¹å¾æƒé‡ã€‚")
    
    st.markdown("""
    **ç²¾ç®€ç‰ˆæŒ‡æ ‡é€‰å–é€»è¾‘ï¼š**
    æ ¹æ® SHAP è´¡çŒ®å›¾ï¼Œ**å¬åŠ›éšœç¢ (hear)** å’Œ **å±…ä½åœ° (rural)** æ˜¯å¯¹è§†åŠ›éšœç¢é¢„æµ‹è´¡çŒ®æœ€å¤§çš„å› ç´ ã€‚
    å¿ƒæ™ºä¸è®¤çŸ¥çŠ¶å†µï¼ˆå¦‚è®¤çŸ¥å¾—åˆ†ã€è®°å¿†è¯„ä»·ï¼‰å¯¹ä¸­è€å¹´è§†åŠ›å¥åº·çš„é¢„æµ‹ä¹Ÿå…·æœ‰æé«˜çš„æ•æ„Ÿåº¦ã€‚
    """)

st.markdown("---")
st.caption("Â© 2025 ç‰¡ä¸¹æ±ŸåŒ»ç§‘å¤§å­¦æŠ¤ç†å­¦é™¢ - æ¢…æŸè±ªå¼€å‘ | ä»…ä¾›ç§‘ç ”å‚è€ƒ")
